{"cells":[{"cell_type":"markdown","metadata":{},"source":["# AI for Classifying Traffic Signals\n","\n","In this notebook, I have created a CNN model to classify images of traffic signals. The signals can be categorized into the following types:\n","- Stop Signs\n","- Crosswalk Signs\n","- Traffic Lights\n","- Speed Limit Signs\n","\n","The dataset used is published on [Kaggle](https://www.kaggle.com/datasets/andrewmvd/road-sign-detection).\n","\n","**Model Architecture**:\n","- **Convolutional Layers**: 3 layers to extract features from images.\n","- **Fully Connected Layers**: 3 layers to make predictions.\n","- **Dropout Layers**: 2 layers added between the fully connected layers to mitigate overfitting.\n","\n","**To Do**:\n","- Handle images of varying sizes; most images are larger than 256x256 pixels.\n","- Experiment with different loss functions and optimizers.\n","- Tune the model with different hyperparameters."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T18:26:56.912902Z","iopub.status.busy":"2024-07-29T18:26:56.912367Z","iopub.status.idle":"2024-07-29T18:27:04.213046Z","shell.execute_reply":"2024-07-29T18:27:04.212227Z","shell.execute_reply.started":"2024-07-29T18:26:56.912875Z"},"trusted":true},"outputs":[],"source":["import os\n","from os import listdir\n","from os.path import isfile, join\n","import xml.etree.ElementTree as ET\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import cv2"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T18:27:04.215092Z","iopub.status.busy":"2024-07-29T18:27:04.214694Z","iopub.status.idle":"2024-07-29T18:27:04.225110Z","shell.execute_reply":"2024-07-29T18:27:04.224333Z","shell.execute_reply.started":"2024-07-29T18:27:04.215066Z"},"trusted":true},"outputs":[],"source":["def parseXML(xmlDir): \n","    onlyfiles = [xmlDir + f for f in listdir(xmlDir) if isfile(join(xmlDir, f))]\n","    data = []\n","    for xmlfile in onlyfiles:\n","        tree = ET.parse(xmlfile)\n","        root = tree.getroot()\n","        obj = {\n","            'filename': root[1].text,\n","            'label': root[4][0].text\n","        }\n","        data.append(obj)\n","    return data\n","\n","def encoder(value):\n","    if value == 'stop':\n","        return 0\n","    elif value == 'trafficlight':\n","        return 1\n","    elif value == 'speedlimit':\n","        return 2\n","    elif value == 'crosswalk':\n","        return 3\n","\n","def decoder(value):\n","    if value == 0:\n","        return 'stop'\n","    elif value == 1:\n","        return 'trafficlight'\n","    elif value == 2:\n","        return 'speedlimit'\n","    elif value == 3:\n","        return 'crosswalk'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T18:27:04.226333Z","iopub.status.busy":"2024-07-29T18:27:04.226079Z","iopub.status.idle":"2024-07-29T18:27:04.245585Z","shell.execute_reply":"2024-07-29T18:27:04.244823Z","shell.execute_reply.started":"2024-07-29T18:27:04.226311Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, dataframe, root_dir, transform=None):\n","        self.data_frame = dataframe\n","        self.root_dir = root_dir\n","        self.transform = transform\n","    def __len__(self):link\n","        return len(self.data_frame)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n","        image = cv2.imread(img_name)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        label = self.data_frame.iloc[idx, -1]\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        return image, label"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T18:27:04.246847Z","iopub.status.busy":"2024-07-29T18:27:04.246609Z","iopub.status.idle":"2024-07-29T18:27:04.255369Z","shell.execute_reply":"2024-07-29T18:27:04.254636Z","shell.execute_reply.started":"2024-07-29T18:27:04.246826Z"},"trusted":true},"outputs":[],"source":["def get_data():\n","    # Load your DataFrame\n","    data = pd.DataFrame(parseXML('/kaggle/input/road-sign-detection/annotations/'))\n","    \n","    data['label'] = data['label'].apply(encoder)\n","\n","    train_df, val_df = train_test_split(data, test_size=0.3, random_state=2024, stratify=data['label'])\n","    transform = transforms.Compose([\n","        transforms.ToPILImage(),\n","        transforms.Resize((256, 256)),\n","        transforms.ToTensor()\n","    ])\n","    root_dir = '/kaggle/input/road-sign-detection/images/'\n","\n","    # Create training and validation datasets\n","    train_dataset = MyDataset(dataframe=train_df, root_dir=root_dir, transform=transform)\n","    val_dataset = MyDataset(dataframe=val_df, root_dir=root_dir, transform=transform)\n","\n","    # Create dataloaders\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","    return train_loader, val_loader\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T18:27:04.257724Z","iopub.status.busy":"2024-07-29T18:27:04.257423Z","iopub.status.idle":"2024-07-29T18:27:06.812448Z","shell.execute_reply":"2024-07-29T18:27:06.811581Z","shell.execute_reply.started":"2024-07-29T18:27:04.257702Z"},"trusted":true},"outputs":[],"source":["train_loader,val_loader = get_data()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T18:27:06.813896Z","iopub.status.busy":"2024-07-29T18:27:06.813620Z","iopub.status.idle":"2024-07-29T18:27:06.824745Z","shell.execute_reply":"2024-07-29T18:27:06.823883Z","shell.execute_reply.started":"2024-07-29T18:27:06.813871Z"},"trusted":true},"outputs":[],"source":["class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        self.fc1 = nn.Linear(64 * 32 * 32, 512)\n","        self.dropout1 = nn.Dropout(p=0.3)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.dropout2 = nn.Dropout(p=0.2)\n","        self.fc3 = nn.Linear(256, 4)\n","        \n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc1(x)\n","        x = self.dropout1(x) \n","        x = self.fc2(x)\n","        x = self.dropout2(x) \n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T18:27:06.826088Z","iopub.status.busy":"2024-07-29T18:27:06.825831Z","iopub.status.idle":"2024-07-29T18:27:06.839871Z","shell.execute_reply":"2024-07-29T18:27:06.839022Z","shell.execute_reply.started":"2024-07-29T18:27:06.826067Z"},"trusted":true},"outputs":[],"source":["def train_model(model, train_loader,device,optimizer,criterion):\n","    model.train()\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    return running_loss\n","    \n","def evaluate_model(model,val_loader,device,optimizer,criterion):\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return (val_loss,correct/total)\n","        \n","def fit_model(model, train_loader, val_loader, num_epochs=15, learning_rate=0.0001, device='cuda'):\n","    model.to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    \n","    print('Starting training. Loss function: CrossEntropyLoss. Optimizer: Adam.')\n","\n","    for epoch in range(num_epochs):\n","        running_loss = train_model(model,train_loader,device,optimizer,criterion)\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n","        val_loss, accuracy = evaluate_model(model,val_loader,device,optimizer,criterion)\n","        print(f'Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * accuracy}%')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T18:27:06.841100Z","iopub.status.busy":"2024-07-29T18:27:06.840827Z","iopub.status.idle":"2024-07-29T18:27:07.219072Z","shell.execute_reply":"2024-07-29T18:27:07.218296Z","shell.execute_reply.started":"2024-07-29T18:27:06.841077Z"},"trusted":true},"outputs":[],"source":["model = MyModel()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T18:27:07.220453Z","iopub.status.busy":"2024-07-29T18:27:07.220163Z","iopub.status.idle":"2024-07-29T18:30:03.622499Z","shell.execute_reply":"2024-07-29T18:30:03.621564Z","shell.execute_reply.started":"2024-07-29T18:27:07.220428Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting training. Loss function: CrossEntropyLoss. Optimizer: Adam.\n","Epoch [1/15], Loss: 2.788779240474105\n","Validation Loss: 1.099358233726687, Accuracy: 74.24242424242425%\n","Epoch [2/15], Loss: 0.9973144014016725\n","Validation Loss: 1.179124878305528, Accuracy: 74.62121212121212%\n","Epoch [3/15], Loss: 0.5481181785464286\n","Validation Loss: 0.8792727766041126, Accuracy: 78.78787878787878%\n","Epoch [4/15], Loss: 0.41270040087401866\n","Validation Loss: 0.9122170051042404, Accuracy: 79.16666666666666%\n","Epoch [5/15], Loss: 0.22360042929649354\n","Validation Loss: 0.7088042265839047, Accuracy: 77.27272727272727%\n","Epoch [6/15], Loss: 0.31818989468738434\n","Validation Loss: 0.9556999074088203, Accuracy: 68.56060606060606%\n","Epoch [7/15], Loss: 0.25712847446557136\n","Validation Loss: 1.1111644241544936, Accuracy: 60.22727272727273%\n","Epoch [8/15], Loss: 0.26873738477006553\n","Validation Loss: 1.2137085224191348, Accuracy: 78.78787878787878%\n","Epoch [9/15], Loss: 0.07038846132345497\n","Validation Loss: 0.8967465338193708, Accuracy: 78.78787878787878%\n","Epoch [10/15], Loss: 0.046293834422249346\n","Validation Loss: 1.2476874163581266, Accuracy: 78.4090909090909%\n","Epoch [11/15], Loss: 0.0815756599418819\n","Validation Loss: 0.9891909774806764, Accuracy: 78.03030303030303%\n","Epoch [12/15], Loss: 0.048857841233257204\n","Validation Loss: 1.3524435733917117, Accuracy: 78.78787878787878%\n","Epoch [13/15], Loss: 0.04028928228653968\n","Validation Loss: 1.0253813018401463, Accuracy: 79.92424242424242%\n","Epoch [14/15], Loss: 0.024151077622082084\n","Validation Loss: 1.2302802327192492, Accuracy: 78.78787878787878%\n","Epoch [15/15], Loss: 0.011008597194449975\n","Validation Loss: 1.3457716591914908, Accuracy: 80.3030303030303%\n"]}],"source":["fit_model(model, train_loader, val_loader)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":671172,"sourceId":1181356,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
